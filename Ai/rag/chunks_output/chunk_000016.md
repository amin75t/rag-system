# Chunk 16

_call=None, tool_calls=None) |
|---|


**Table 8**

| import os
import asyncio
from langfuse.openai import AsyncOpenAI
from langfuse import observe, get_client

openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
langfuse_client = get_client()

PROMPT_NAME = "test-system-prompt"

@observe
async def call_llm():
    prompt = langfuse_client.get_prompt(PROMPT_NAME)
    response = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": prompt.prompt},
            {"role": "user", "content": "سلام"},
        ],
    )
    print(response.choices[0].message)
    return response

asyncio.

---

